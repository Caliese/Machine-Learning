{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Ode3bXydoY7a"
      },
      "outputs": [],
      "source": [
        "# Copyright (c) MONAI Consortium\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install monai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aosKjXAfq1E8",
        "outputId": "a4d01715-1501-4b70-94c0-ca858f6743fe"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: monai in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.10/dist-packages (from monai) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import tempfile\n",
        "from glob import glob\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import monai\n",
        "from monai.data import ArrayDataset, create_test_image_2d, decollate_batch, DataLoader\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.transforms import (\n",
        "    Activations,\n",
        "    AsDiscrete,\n",
        "    Compose,\n",
        "    LoadImage,\n",
        "    RandRotate90,\n",
        "    RandSpatialCrop,\n",
        "    ScaleIntensity,\n",
        "    Lambda,\n",
        ")\n",
        "from monai.visualize import plot_2d_or_3d_image"
      ],
      "metadata": {
        "id": "vwTGIJuEojFj"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(image_dir):\n",
        "    monai.config.print_config()\n",
        "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "\n",
        "    # Use your own images by specifying the directory where they are stored\n",
        "    images = sorted(glob(os.path.join(image_dir, \"img*.png\")))  # Adjust the pattern to match your image names\n",
        "    segs = sorted(glob(os.path.join(image_dir, \"seg*.png\")))    # Adjust the pattern to match your mask names\n",
        "\n",
        "    if len(images) == 0 or len(segs) == 0:\n",
        "        print(\"No images or segmentation masks found in the specified directory.\")\n",
        "        return\n",
        "\n",
        "    # create a temporary directory and 40 random image, mask pairs\n",
        "    #print(f\"generating synthetic data to {tempdir} (this may take a while)\")\n",
        "    #for i in range(40):\n",
        "        #im, seg = create_test_image_2d(128, 128, num_seg_classes=1)\n",
        "        #Image.fromarray((im * 255).astype(\"uint8\")).save(os.path.join(tempdir, f\"img{i:d}.png\"))\n",
        "        #Image.fromarray((seg * 255).astype(\"uint8\")).save(os.path.join(tempdir, f\"seg{i:d}.png\"))\n",
        "\n",
        "\n",
        "\n",
        "    images = sorted(glob(os.path.join(image_dir, \"img*.png\")))\n",
        "    segs = sorted(glob(os.path.join(image_dir, \"seg*.png\")))\n",
        "    print(images)\n",
        "    print(segs)\n",
        "\n",
        "    # define transforms for image and segmentation\n",
        "    train_imtrans = Compose(\n",
        "        [\n",
        "            LoadImage(image_only=True, ensure_channel_first=True),\n",
        "            Lambda(lambda x: x.mean(axis=0, keepdims=True)), #convert to grayscale\n",
        "            ScaleIntensity(),\n",
        "            RandSpatialCrop((96, 96), random_size=False),\n",
        "            RandRotate90(prob=0.5, spatial_axes=(0, 1)),\n",
        "        ]\n",
        "    )\n",
        "    train_segtrans = Compose(\n",
        "        [\n",
        "            LoadImage(image_only=True, ensure_channel_first=True),\n",
        "            Lambda(lambda x: x.mean(axis=0, keepdims=True)), #convert to grayscale\n",
        "            ScaleIntensity(),\n",
        "            RandSpatialCrop((96, 96), random_size=False),\n",
        "            RandRotate90(prob=0.5, spatial_axes=(0, 1)),\n",
        "        ]\n",
        "    )\n",
        "    val_imtrans = Compose(\n",
        "        [\n",
        "            LoadImage(image_only=True, ensure_channel_first=True),\n",
        "            Lambda(lambda x: x.mean(axis=0, keepdims=True)), #convert to grayscale\n",
        "            ScaleIntensity(),\n",
        "        ]\n",
        "    )\n",
        "    val_segtrans = Compose(\n",
        "        [LoadImage(image_only=True, ensure_channel_first=True),\n",
        "         Lambda(lambda x: x.mean(axis=0, keepdims=True)), #convert to grayscale\n",
        "         ScaleIntensity()\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # define array dataset, data loader\n",
        "    check_ds = ArrayDataset(images, train_imtrans, segs, train_segtrans)\n",
        "    check_loader = DataLoader(check_ds, batch_size=10, num_workers=2, pin_memory=torch.cuda.is_available())\n",
        "    im, seg = monai.utils.misc.first(check_loader)\n",
        "    print(im.shape, seg.shape)\n",
        "\n",
        "    # create a training data loader\n",
        "    train_ds = ArrayDataset(images[:20], train_imtrans, segs[:20], train_segtrans)\n",
        "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=8, pin_memory=torch.cuda.is_available())\n",
        "    # create a validation data loader\n",
        "    val_ds = ArrayDataset(images[-20:], val_imtrans, segs[-20:], val_segtrans)\n",
        "    val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, pin_memory=torch.cuda.is_available())\n",
        "    dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
        "    post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
        "    # create UNet, DiceLoss and Adam optimizer\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = monai.networks.nets.UNet(\n",
        "        spatial_dims=2,\n",
        "        in_channels=1,\n",
        "        out_channels=1,\n",
        "        channels=(16, 32, 64, 128, 256),\n",
        "        strides=(2, 2, 2, 2),\n",
        "        num_res_units=2,\n",
        "    ).to(device)\n",
        "    loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
        "\n",
        "    # start a typical PyTorch training\n",
        "    val_interval = 2\n",
        "    best_metric = -1\n",
        "    best_metric_epoch = -1\n",
        "    epoch_loss_values = list()\n",
        "    metric_values = list()\n",
        "    writer = SummaryWriter()\n",
        "    for epoch in range(10):\n",
        "        print(\"-\" * 10)\n",
        "        print(f\"epoch {epoch + 1}/{10}\")\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        step = 0\n",
        "        for batch_data in train_loader:\n",
        "            step += 1\n",
        "            inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_len = len(train_ds) // train_loader.batch_size\n",
        "            print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
        "            writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
        "        epoch_loss /= step\n",
        "        epoch_loss_values.append(epoch_loss)\n",
        "        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "        if (epoch + 1) % val_interval == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_images = None\n",
        "                val_labels = None\n",
        "                val_outputs = None\n",
        "                for val_data in val_loader:\n",
        "                    val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
        "                    roi_size = (96, 96)\n",
        "                    sw_batch_size = 4\n",
        "                    val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
        "                    val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
        "                    # compute metric for current iteration\n",
        "                    dice_metric(y_pred=val_outputs, y=val_labels)\n",
        "                # aggregate the final mean dice result\n",
        "                metric = dice_metric.aggregate().item()\n",
        "                # reset the status for next validation round\n",
        "                dice_metric.reset()\n",
        "                metric_values.append(metric)\n",
        "                if metric > best_metric:\n",
        "                    best_metric = metric\n",
        "                    best_metric_epoch = epoch + 1\n",
        "                    torch.save(model.state_dict(), \"best_metric_model_segmentation2d_array.pth\")\n",
        "                    print(\"saved new best metric model\")\n",
        "                print(\n",
        "                    \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n",
        "                        epoch + 1, metric, best_metric, best_metric_epoch\n",
        "                    )\n",
        "                )\n",
        "                writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n",
        "                # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
        "                plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
        "                plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
        "                plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n",
        "\n",
        "    print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
        "    writer.close()"
      ],
      "metadata": {
        "id": "Kikr6KT6oyk2"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    image_dir = \"/content/sample_data\"  # specify your image directory path here\n",
        "    main(image_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RZLrErW7pDbq",
        "outputId": "b49acc53-61a5-453a-813e-df604906e5b3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MONAI version: 1.4.0\n",
            "Numpy version: 1.26.4\n",
            "Pytorch version: 2.5.1+cu121\n",
            "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
            "MONAI rev id: 46a5272196a6c2590ca2589029eed8e4d56ff008\n",
            "MONAI __file__: /usr/local/lib/python3.10/dist-packages/monai/__init__.py\n",
            "\n",
            "Optional dependencies:\n",
            "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "Nibabel version: 5.3.2\n",
            "scikit-image version: 0.25.0\n",
            "scipy version: 1.13.1\n",
            "Pillow version: 11.1.0\n",
            "Tensorboard version: 2.17.1\n",
            "gdown version: 5.2.0\n",
            "TorchVision version: 0.20.1+cu121\n",
            "tqdm version: 4.67.1\n",
            "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "psutil version: 5.9.5\n",
            "pandas version: 2.2.2\n",
            "einops version: 0.8.0\n",
            "transformers version: 4.47.1\n",
            "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "\n",
            "For details about installing the optional dependencies, please visit:\n",
            "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
            "\n",
            "['/content/sample_data/img1.png', '/content/sample_data/img2.png', '/content/sample_data/img3.png']\n",
            "['/content/sample_data/seg1.png', '/content/sample_data/seg2.png', '/content/sample_data/seg3.png', '/content/sample_data/seg6.png', '/content/sample_data/seg8.png']\n",
            "torch.Size([3, 1, 96, 96]) torch.Size([3, 1, 96, 96])\n",
            "----------\n",
            "epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/0, train_loss: 0.4977\n",
            "epoch 1 average loss: 0.4977\n",
            "----------\n",
            "epoch 2/10\n",
            "1/0, train_loss: 0.5352\n",
            "epoch 2 average loss: 0.5352\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (154) must match the size of tensor b (1204) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-a72695eda20c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimage_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/sample_data\"\u001b[0m  \u001b[0;31m# specify your image directory path here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-41-3e41717faecc>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(image_dir)\u001b[0m\n\u001b[1;32m    127\u001b[0m                     \u001b[0mval_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpost_trans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecollate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0;31m# compute metric for current iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                     \u001b[0mdice_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m                 \u001b[0;31m# aggregate the final mean dice result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdice_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/monai/metrics/metric.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_pred, y, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHWD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \"\"\"\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/monai/metrics/metric.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_pred, y, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# handling a list of channel-first data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;31m# handling a single batch-first data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/monai/metrics/metric.py\u001b[0m in \u001b[0;36m_compute_list\u001b[0;34m(self, y_pred, y, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \"\"\"\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             ret = [\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/monai/metrics/metric.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             ret = [\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/monai/metrics/meandice.py\u001b[0m in \u001b[0;36m_compute_tensor\u001b[0;34m(self, y_pred, y)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"y_pred should have at least 3 dimensions (batch, channel, spatial), got {dims}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# compute dice (BxC) for each channel for each batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdice_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     def aggregate(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/monai/metrics/meandice.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_pred, y)\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0mx_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                 \u001b[0mc_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_channel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/monai/metrics/meandice.py\u001b[0m in \u001b[0;36mcompute_channel\u001b[0;34m(self, y_pred, y)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0my_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_o\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_o\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/monai/data/meta_tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__torch_function__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;31m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;31m# if \"out\" in kwargs:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunctionSubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1512\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1513\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_default_nowrap_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (154) must match the size of tensor b (1204) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#if __name__ == \"__main__\":\n",
        "    #with tempfile.TemporaryDirectory() as tempdir:\n",
        "        #main(tempdir)"
      ],
      "metadata": {
        "id": "B2v-L8VmisVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "s-FErMie28Bq"
      }
    }
  ]
}